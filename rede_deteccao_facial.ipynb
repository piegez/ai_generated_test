{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOtQ+Bg/gKuOPvssMlg/yao",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/piegez/ai_generated_test/blob/main/rede_deteccao_facial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando as bibliotecas necessárias\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import fetch_lfw_people\n",
        "\n",
        "# Carregando o dataset LFW\n",
        "print(\"Carregando o dataset...\")\n",
        "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
        "\n",
        "# Obtendo os dados e labels\n",
        "X = lfw_people.images\n",
        "y = lfw_people.target\n",
        "target_names = lfw_people.target_names\n",
        "\n",
        "# Dividindo os dados em treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Pré-processando as imagens\n",
        "X_train = np.repeat(X_train[..., np.newaxis], 3, -1)  # Convertendo para 3 canais\n",
        "X_test = np.repeat(X_test[..., np.newaxis], 3, -1)\n",
        "X_train = tf.image.resize(X_train, (224, 224)).numpy()\n",
        "X_test = tf.image.resize(X_test, (224, 224)).numpy()\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# Criando o modelo\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "output = Dense(len(target_names), activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compilando o modelo\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.0001),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Treinando o modelo\n",
        "print(\"Iniciando treinamento...\")\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Plotando o histórico de treinamento\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Acurácia (treino)')\n",
        "plt.plot(history.history['val_accuracy'], label='Acurácia (validação)')\n",
        "plt.title('Acurácia do Modelo')\n",
        "plt.xlabel('Época')\n",
        "plt.ylabel('Acurácia')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Perda (treino)')\n",
        "plt.plot(history.history['val_loss'], label='Perda (validação)')\n",
        "plt.title('Perda do Modelo')\n",
        "plt.xlabel('Época')\n",
        "plt.ylabel('Perda')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Avaliando o modelo\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Acurácia no conjunto de teste: {test_acc:.4f}\")\n",
        "\n",
        "# Função para detectar e reconhecer faces\n",
        "def detect_and_recognize_faces(image):\n",
        "    # Pré-processamento da imagem\n",
        "    image = tf.image.resize(image, (224, 224))\n",
        "    image = tf.expand_dims(image, 0)\n",
        "\n",
        "    # Fazendo a predição\n",
        "    prediction = model.predict(image)\n",
        "    person_id = tf.argmax(prediction[0]).numpy()\n",
        "    confidence = tf.reduce_max(prediction[0]).numpy()\n",
        "\n",
        "    return person_id, confidence\n",
        "\n",
        "# Testando o modelo em algumas imagens do conjunto de teste\n",
        "print(\"\\nTestando o modelo em algumas imagens...\")\n",
        "for i in range(5):\n",
        "    idx = np.random.randint(len(X_test))\n",
        "    image = X_test[idx]\n",
        "    true_label = y_test[idx]\n",
        "\n",
        "    person_id, confidence = detect_and_recognize_faces(image)\n",
        "\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(image)\n",
        "    plt.title(f'Predição: {target_names[person_id]}\\nConfiança: {confidence:.2f}\\nLabel Real: {target_names[true_label]}')\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBlug_bx2Sp6",
        "outputId": "e0f143c9-306a-48ef-c807-82f09426f21e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Carregando o dataset...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Iniciando treinamento...\n",
            "Epoch 1/10\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:38\u001b[0m 7s/step - accuracy: 0.3068 - loss: 1.7665"
          ]
        }
      ]
    }
  ]
}